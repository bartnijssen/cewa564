{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: SUMMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now you have learned how to import `pysumma`, but we still have not run SUMMA yet. In this notebook we will take you through some sample SUMMA simulations that will make it possible for you to do some actual exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that you want to save your notebooks in a place other than the `demo` directory tree, because files you save there may be overwritten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SUMMA example that we'll run through will reproduce Figure 7 in [Clark et al. (2015)](http://doi.org/10.1002/2015WR017200). The team at the [Hydroinformatics Research Group at the University of Virginia](https://uvahydroinformatics.org/) converted the example to use `pysumma`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line just ensures that any plots we create in this notebook will be visible in your notebook (it's called a [magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) command)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to stomatal resistance parameterizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One part of the [Clark et al. (2015)](http://doi.org/10.1002/2015WR017200) paper explored the impact of different stomatal resistance parameterizations in SUMMA on simulated total evapotranspiration (ET) for the Reynolds Mountain East catchment. They used three stomatal resistance parameterizations in SUMMA: the simple resistance method, the Ball Berry method, and the Jarvis method. We don't describe the methods in any detail here, but focus on how to run SUMMA.\n",
    "\n",
    "In this Jupyter notebook, the `pysumma` library is used to reproduce this analysis. We show how `pysumma` can be used to create three different versions of the Reynolds Mountain East catchment model, one for each stomatal resistance parameterization. Along the way, we'll show you how you can conduct your SUMMA simulations using `pysumma` in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and install the SUMMA test cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you continue, we will need to install the SUMMA test cases in your virtual machine. You will only need to do this once (unless things really go wrong and you want to re-install them). To install the SUMMA test cases, open the notebook `install_summa_model_configurations.ipynb` in the `/home/jovyan/cewa564` directory and follow the instructions. After you have done so, continue here.\n",
    "\n",
    "For now, don't modify the path where the test cases are installed, because it is hardcoded in some of the SUMMA input files for the purpose of this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the place where the test cases are installed (so we don't need to type it every time)\n",
    "testcase_path = '/home/jovyan/summaTestCases_2.x_b074b0ffa'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full path to the SUMMA test cases is now stored in `testcase_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look at these directories in the file manager on the left, but there is nothing else you currently need to do with this. Now that the SUMMA setups are available on your virtual machine, we can create a `pysumma` simulation object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and configure a `pysumma` simulation object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pysumma` allows you to create a simulation object that contains all the information needed to run a SUMMA simulation. The object is fairly simple, but contains the locations of all the input files and allows you to interact with the SUMMA configuration files, without you having to edit individual files and figuring out which information goes where. \n",
    "\n",
    "We'll create a simulation object and then configure that simulation object for our SUMMA model run. When we create the simulation object, we have to provide it with name of the SUMMA executable and the path to the main input file for SUMMA (file manager file). The SUMMA executable installed in this virtual machine is `summa.exe` and is already in your path. The main input file is part of the test cases that we installed in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysumma as ps\n",
    "import os.path\n",
    "\n",
    "# create a `pysumma` simulation object. \n",
    "filemanager_path = os.path.join(testcase_path, 'settings/wrrPaperTestCases/figure07/summa_fileManager_riparianAspenSimpleResistance.txt')\n",
    "S = ps.Simulation(executable='summa.exe', filemanager=filemanager_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation object contains information about the model decisions that should be used for the SUMMA simulations. More information about the decisions can be found in the [SUMMA documentation](https://summa.readthedocs.io/en/latest/input_output/SUMMA_input/#infile_model_decisions). To examine the model decisions that are being used by the simulation object `S`, you can simple print the `S.decisions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(ps.Simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also query the available options for a particular model decisions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.decisions.stomResist.available_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to be somewhat careful though. Some of these options are only used to test SUMMA code (like the `BallBerryTest` option). Unfortunately there is no good way to know this advance, so when in doubt, just ask (the code is always the best documentation, but the code isn't particularly easy to read, even if you do know Fortran),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first simulations we will use the `simpleResistance` option. We will also set the start (`simulStart`) and end (`simulEnd`) time of the simulations. To set an option, you can use `S.decisions.<decision>.set_value(<option>)`, so in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the simulation start and finish times\n",
    "S.decisions.simulStart.set_value(\"2006-07-01 00:00\")\n",
    "S.decisions.simulFinsh.set_value(\"2007-08-20 00:00\")\n",
    "\n",
    "# set the stomatal resistance option\n",
    "S.decisions.stomResist.set_value('simpleResistance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are all set to perform the actual SUMMA simulation. Note that there are many more decisions, output options and model parameters that we can change, but we'll use the settings that were already configured for the test case. Configuring SUMMA from scratch requires a lot more effort than this. But for this example we can move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run SUMMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running SUMMA is now easy. We will use the Simulation object to run the simulation. The model will write an output file, which will then be read directly into the simulation object, and which can then be accessed as `S.output`. SUMMA output files use the [NetCDF format](https://www.unidata.ucar.edu/software/netcdf/), which is widely use in earth science (particularly atmospheric science and hydrology).\n",
    "\n",
    "To run the model, we will use `S.start()`. Note that you can get some basic help on `pysumma` functions by just typing: `help(S.start)`, for example, you can execute the following cell, to get some additional information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(S.start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will us `'local'` for the `run_option` (the other one is `docker`), but because SUMMA is locally installed in the virtual machine we do not need that (don't worry if this means nothing to you at this time). We will also specify a `run_suffix` that becomes part of the  output file names so that we can distinguish multiple simulations.\n",
    "\n",
    "In addition to `S.start()`, we will also need to run `S.monitor()`, which checks in the background whether the runs is finished.\n",
    "\n",
    "When you execute the following step. If everything works as it should, then it will run the message `False`, which is admittedly confusing and something we should change. This first model run should only take a few seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.start(run_option='local', run_suffix='simple')\n",
    "S.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, SUMMA ran to completion and you can access the messages that the model sent to the screen in `S.stdout` and `S.stderr`. For example, the messages are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stdout:\\n-------\\n{}\\n========\\n'.format(S.stdout))\n",
    "print('stderr:\\n-------\\n{}\\n========\\n'.format(S.stderr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results object `S.output` contains an [xarray](http://xarray.pydata.org/en/stable/) Dataset with all the SUMMA output variables that were specified in your setup (you can change this, we'll show this later). This same information is also stored in the SUMMA output file, but we don't need to read that one directly. If you are already familiar with xarray, then you can do a lot of your analysis with `S.output`. Teaching you xarray is beyond the scope of this course, but if you know about it then you can do things like (don't worry if you get a warning, as long as a plot appears you are all good to go on, if it doesn't, execute the cell once more to make the warning go away and the plot appear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Snow Water Equivalent time series\n",
    "S.output.scalarSWE.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, you could quickly calculate derived quantities like the mean snow water equivalent (SWE) by month and plot it (again don't worry if you get a warning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean air temperature by month\n",
    "S.output.scalarSWE.isel(hru=0).resample(time='M').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations. You did your first SUMMA simulation. We will now configure two more simulation objects and do the same simulations with two different options for `stomResist`. In a later notebook we will show you how to run all three simulations at once, using `pysumma`'s `ensemble` capability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create, configure, and run two more SUMMA instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure SUMMA with the `BallBerry` option for stomatal resistance and run. We will create a new simulation object for each run, by first making a copy of the `S` simulation object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "S_simple = copy.copy(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_ballberry = copy.copy(S)\n",
    "S_ballberry.decisions.stomResist.set_value('BallBerry')\n",
    "S_ballberry.start(run_option = 'local', run_suffix=\"ballberry\")\n",
    "S_ballberry.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more time with the `Jarvis` option for stomatal resistance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_jarvis = copy.copy(S)\n",
    "S_jarvis.decisions.stomResist.set_value('Jarvis')\n",
    "S_jarvis.start(run_option = 'local', run_suffix=\"jarvis\")\n",
    "S_jarvis.monitor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to demonstrate that the results really are different, we can quickly plot the monthly latent heat flux using xarray (since we would expect that changing the stomatal resistance would change the latent heat flux). The sign convention in SUMMA is that a flux away from the surface is negative (again, just ignore the warnings). The units are in $W/m^{-2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the monthly total latent heat flux time series\n",
    "import matplotlib.pyplot as plt\n",
    "S_simple.output.scalarLatHeatTotal.isel(hru=0).resample(time='M').mean().plot(label='simple')\n",
    "S_ballberry.output.scalarLatHeatTotal.isel(hru=0).resample(time='M').mean().plot(label='Ball-Berry')\n",
    "S_jarvis.output.scalarLatHeatTotal.isel(hru=0).resample(time='M').mean().plot(label='Jarvis')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snow water equivalent on the other hand remains relatively unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the monthly snow water equivalent time series\n",
    "S_simple.output.scalarSWE.isel(hru=0).resample(time='M').mean().plot(label='simple')\n",
    "S_ballberry.output.scalarSWE.isel(hru=0).resample(time='M').mean().plot(label='Ball-Berry')\n",
    "S_jarvis.output.scalarSWE.isel(hru=0).resample(time='M').mean().plot(label='Jarvis')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce Figure 7 in Clark et al. (2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is pretty specific to the reproduction of Figure 7 in Clark et al. (2015) and can be simplified by using some more xarray capabilities. Don't worry about the actual code here. We just want to demonstrate that the SUMMA simulations that you just performed are basically the same as those that were used in the SUMMA paper (they are slightly different because SUMMA itself has changed a bit). Just run the code in the next few cells and look at the output and compare it to Figure 7 in Clark et al. (2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some more plotting functionality and some packages\n",
    "from pysumma.plotting import plotting\n",
    "from jupyterthemes import jtplot\n",
    "import pandas as pd\n",
    "\n",
    "# set the figure size in the notebook\n",
    "jtplot.figsize(x=10, y=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculation the total evapotranspiration by hour\n",
    "def calc_total_et(et_output_df):\n",
    "    # Total Evapotranspiration = Canopy Transpiration + Canopy Evaporation + Ground Evaporation\n",
    "    # Change unit from kgm-2s-1 to mm/hr (mulpitle 3600)\n",
    "    total_et_data = (et_output_df['scalarCanopyTranspiration'] + et_output_df['scalarCanopyEvaporation'] + et_output_df['scalarGroundEvaporation'])*3600\n",
    "    # create dates(X-axis) attribute from ouput netcdf\n",
    "    dates = total_et_data.coords['time'].data\n",
    "    # create data value(Y-axis) attribute from ouput netcdf\n",
    "    data_values = total_et_data.data\n",
    "    # create two dimensional tabular data structure \n",
    "    total_et_df = pd.DataFrame(data_values, index=dates)\n",
    "    # round time to nearest hour (ex. 2006-10-01T00:59:59.99 -> 2006-10-01T01:00:00)\n",
    "    total_et_df.index = total_et_df.index.round(\"H\")\n",
    "    # set the time period to display plot \n",
    "    total_et_df = total_et_df.loc[\"2007-06-01\":\"2007-08-20\"]\n",
    "    # resample data by the average value hourly\n",
    "    total_et_df_hourly = total_et_df.resample(\"H\").mean()\n",
    "    # resample data by the average for hour of day\n",
    "    total_et_by_hour = total_et_df_hourly.groupby(total_et_df_hourly.index.hour).mean()\n",
    "    return total_et_by_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total ET by hour for the three stomatal resistance implementations\n",
    "results_simple_hour = calc_total_et(S_simple.output)\n",
    "results_ballberry_hour = calc_total_et(S_ballberry.output)\n",
    "results_jarvis_hour = calc_total_et(S_jarvis.output)\n",
    "\n",
    "# Combine the results into a single data frame\n",
    "ET_Combine = pd.concat([results_ballberry_hour, results_jarvis_hour, results_simple_hour], axis=1)\n",
    "ET_Combine.columns = ['Ball-Berry', 'Jarvis', 'Simple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read observation data from file\n",
    "# create `pysumma` Plotting Object\n",
    "Val_eddyFlux = plotting.Plotting(testcase_path+'/testCases_data/validationData/ReynoldsCreek_eddyFlux.nc')\n",
    "# read Total Evapotranspiration(LE-wpl) from validation netcdf file\n",
    "Obs_Evapotranspitaton = Val_eddyFlux.ds['LE-wpl']\n",
    "# create dates(X-axis) attribute from validation netcdf file\n",
    "dates = Obs_Evapotranspitaton.coords['time'].data\n",
    "# Change unit from Wm-2 to mm/hr (1 Wm-2 = 0.0864 MJm-2day-1, 1 MJm-2day-1 = 0.408 mmday-1, 1day = 24h)\n",
    "data_values = Obs_Evapotranspitaton.data*0.0864*0.408/24\n",
    "# create two dimensional tabular data structure \n",
    "df = pd.DataFrame(data_values, index=dates)\n",
    "# set the time period to display plot\n",
    "df_filt = df.loc[\"2007-06-01\":\"2007-08-20\"]\n",
    "# select aspen obervation station among three different stations\n",
    "df_filt.columns = ['-','Observation (aspen)','-']\n",
    "# resample data by the average for hour of day\n",
    "df_gp_hr = df_filt.groupby([df_filt.index.hour, df_filt.index.minute]).mean()\n",
    "# reset index so each row has an hour an minute column\n",
    "df_gp_hr.reset_index(inplace=True)\n",
    "# add hour and minute columns for plotting\n",
    "xvals = df_gp_hr.reset_index()['level_0'] + df_gp_hr.reset_index()['level_1']/60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display the plot\n",
    "ET_Combine_Graph = ET_Combine.plot(legend=False)\n",
    "# invert y axis\n",
    "ET_Combine_Graph.invert_yaxis()\n",
    "\n",
    "ET_Combine_Graph.plot(ET_Combine['Ball-Berry'],color='b', marker='^') \n",
    "ET_Combine_Graph.plot(ET_Combine['Jarvis'], color='g', marker='o')\n",
    "ET_Combine_Graph.plot(ET_Combine['Simple'], color='y', marker='d')\n",
    "\n",
    "ET_Combine_Graph.tick_params(labelsize = 15)\n",
    "# plot scatter with x='xvals', y='Observation (aspen)'\n",
    "d = ET_Combine_Graph.scatter(xvals, df_gp_hr['Observation (aspen)'], color='black')\n",
    "# add x, y label\n",
    "ET_Combine_Graph.set_xlabel(\"Time of day (hr)\", fontsize=18)\n",
    "ET_Combine_Graph.set_ylabel(\"Total evapotranspiration (mm h-1)\", fontsize=18)\n",
    "\n",
    "handles, labels = ET_Combine_Graph.get_legend_handles_labels()\n",
    "# show up the legend\n",
    "ET_Combine_Graph.legend(handles[3:7], labels[3:7])\n",
    "jtplot.figsize(x=10, y=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again note that the ET fluxes are negative because of SUMMA's sign convention (negative away from the surface). Don't worry if the plotting code is not clear to you. You can make your own plots in the homework assignments. **NOTE THAT THERE IS A PROBLEM WITH A TIME OFFSET IN THIS SIMULATION, THIS WILL BE FIXED SHORTLY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting your data to ASCII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Generally I would encourage you to do your analysis in the notebook, because it will prevent the need to upload / download files. However, if this is really too much work, then you can download the files to your own machine and process them there.\n",
    "\n",
    "To download the files, you can navigate to them with the file manager and then download them from there. For example, the output files for this simulation are in \n",
    "`/home/jovyan/summaTestCases_2.x_b074b0ffa/output/wrrPaperTestCases/figure07/`\n",
    "\n",
    "There you will find three files with the run suffixes we specified earlier.\n",
    "\n",
    "* vegImpactsTranspire_output_ballberry_timestep.nc\n",
    "* vegImpactsTranspire_output_simple_timestep.nc\n",
    "* vegImpactsTranspire_output_jarvis_timestep.nc\n",
    "\n",
    "All these files have the `.nc` extension, which by convention indicates that the files are in the [NetCDF format](https://www.unidata.ucar.edu/software/netcdf/). If you are not familiar with this format, then it would be a good idea for your research career to learn how to read them. A lot of analysis software will be able to read NetCDF files directly or through the use of some add-ons (this includes python, R, matlab, etc.). Some of the nice features of NetCDF files are that the metadata is part of the files themselves, the files are machine-independent, and they are great for storing multi-dimensional data. For example, the SUMMA NetCDF files include the settings for the model decisions as part of the metadata.\n",
    "\n",
    "To download these files, you can right-click on them and select 'Download'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in general, if you can read the NetCDF files directly into your analysis software that is the preferred way to go. However, this course is not long enough to teach you how to do all this and you can learn much of this on your own. If you are not able to read NetCDF files, the easiest way to proceed is to export some of the data as csv files (_comma-separated values_), which can be read by almost any analysis software. You can do that on your local machine, but here we'll show you how to export some of your data to csv and add it to your existing HydroShare resource. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, let's export `scalarSWE` for the `simple` case and then also export `mLayerTemp`, which is the temperature for each layer (soil and snow).\n",
    "\n",
    "Note that these variables have different dimensions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_simple.output[['scalarSWE']].dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_simple.output[['mLayerTemp']].dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scalarSWE` is defined along the `hru` and `time` dimensions, while `mLayerTemp` is defined along the `midToto`, `hru`, and `time` dimensions. \n",
    "\n",
    "An `hru` is a _hydrologic response unit_ and is the smallest spatial element in SUMMA. Since we are doing point simulations, there is only one `hru` element, so we can drop it when we write the output as ASCII. \n",
    "\n",
    "The `midToto` dimension reflects the number of layers (including both soil and snow layers). Since we have a different `mLayerTemp` for each soil and snow layer, we need to store a value for each layer for each timestep.\n",
    "\n",
    "The `time` dimension simply reflects the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use some xarray and [pandas](http://pandas.pydata.org/) (another really useful python package) functionality to write these variables to csv files. To make your csv files easier to manage, it is best to write the files so that all variables in a single file have the same dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's export `scalarSWE` and store it in `swe_file` that we will then add to your existing HydroShare resource. It's up to you to give the files meaningful names and to make sure that you are pointing to the right files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swe_simple_file = os.path.join(testcase_path, 'output/wrrPaperTestCases/figure07/swe_export_simple.csv')\n",
    "S_simple.output[['scalarSWE']].drop('hru').squeeze().to_dataframe().to_csv(swe_simple_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's step through this. \n",
    "* select the variable `scalarSWE` in the `results_simple` DataSet: `results_simple[['scalarSWE']]`\n",
    "* drop the `hru` dimension : `.drop('hru')`\n",
    "* drop any unused dimenions : `.squeeze()`\n",
    "* convert the result to a pandas dataframe : `.to_dataframe()`\n",
    "* save the results as a csv file to `swe_simple_file` : `.to_csv(swe_simple_file)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you navigate to the file manager on your left, you can find the file and open it to make sure it looks as you'd expect. Let's now save `mLayerTemp` as well (to a different file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlayertemp_simple_file = os.path.join(testcase_path, 'output/wrrPaperTestCases/figure07/mlayertemp_export_simple.csv')\n",
    "S_simple.output[['mLayerTemp']].drop('hru').squeeze().to_dataframe().to_csv(mlayertemp_simple_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look at this file, you will notice that there is an additional column labeled `midToto` with the layer number. I'm not sure what the easiest way is to process this data in your favorite analysis software, but that is for you to find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On to the next step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this notebook and close the tab. You can also right-click on the file in the left panel if it has a green dot next to it and select \"_Shutdown kernel_\" from the popup menu to stop the python session that is executing the commands in this notebook.  **TO BE CONTINUED ...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clark, M. P., B. Nijssen, J. Lundquist, D. Kavetski, D. Rupp, R. Woods, J. Freer, E. Gutmann, A. Wood, D. Gochis, R. Rasmussen, D. Tarboton, V. Mahat, G. Flerchinger, D. Marks, 2015: A unified approach for process-based hydrologic modeling: Part 2. Model implementation and case studies. _Water Resources Research_, [doi:10.1002/2015WR017200](http://doi.org/10.1002/2015WR017200)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
